model_list:
  - model_name: gpt-3.5-turbo
    llm_params:
      model: openai/gpt-3.5-turbo

# Set to `true` to allow dynamic model list add/edit
general_settings:
  store_model_in_db: true
  database_url: "postgresql://llmproxy:dbpassword9090@db:5432/llm"

# Set Cache (Redis/in-memory) to improve performance. Cache is now managed across multiple llm Proxy servers
# cache:
#   type: redis                # Required: Options include "redis" or "in-memory".
#   host: redis
#   port: 6379
#   password: ${REDIS_PASSWORD:-litevp}
#   time_to_live: 3600        # Time in seconds for which cached responses are valid.
#   cache_langchain_calls: True
